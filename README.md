# PyTorch-TinyBERT

PyTorch-TinyBERT is a from-scratch implementation of a lightweight BERT-like model with 2â€“4 transformer layers for text classification tasks such as IMDB and AG News. The project is designed for reproducibility, includes a CLI interface for training and evaluation, and provides comparisons with Hugging Face pretrained models. It aims to serve as a compact, research-oriented framework to study transformer efficiency and performance on resource-constrained hardware like the RTX 4060.  

This project is licensed under the MIT License.  

This project is currently under work.

